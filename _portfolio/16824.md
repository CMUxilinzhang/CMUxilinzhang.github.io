---
title: "Proprio-Phys: Physical Property Estimation under Occlusion"
excerpt: >
  A multimodal perception framework that estimates friction, stiffness, mass, and contact torque under egocentric occlusion.<br/>
#   <img src="/images/proprio-phys.png">
collection: portfolio
---


## Introduction  
Contact-rich manipulation often suffers from **severe occlusion**, making vision-only pipelines unreliable. This project develops *Proprio-Phys*, a multimodal perception system that estimates friction, stiffness, mass, and contact torque using partial vision and proprioception. The broader goal is to enable **more robust, physics-aware robotic manipulation** in homes, factories, and assistive robotics scenarios.  
**Objective:** recover key physical properties even when the gripper or object blocks the camera.

## Methods  
Our pipeline (from :contentReference[oaicite:1]{index=1}) integrates:  
- **Diffusion-based 3D completion** to reconstruct occluded geometry.  
- **CNN + Transformer encoders** for spatial feature extraction.  
- **LSTM + temporal Transformer** for modeling stickâ€“slip and multi-phase contact.  
- **Physics-informed losses** enforcing friction cones, complementarity, and energy consistency.

## Results  
We expect the system to:  
- Reduce friction / stiffness estimation error by **>30%** compared to vision-only baselines.  
- Improve contact-torque prediction under heavy occlusion.  
- Enable more stable impedance and force-aware control.

## Discussion  
The system complements FOAR-style reasoning and extends beyond vision-language affordance models by explicitly predicting physical parameters. The framework is designed for seamless integration with controllers and real-world robot tasks.

## My Contribution  
I worked on system design, multimodal fusion strategy, physics-informed loss formulation, and writing the overall proposal.  
